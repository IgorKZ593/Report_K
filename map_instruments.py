#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
map_instruments.py ‚Äî –≠—Ç–∞–ø 1.
–ö–∞—Ä–∫–∞—Å: –ø–æ–∏—Å–∫ –≤—Ö–æ–¥–Ω–æ–≥–æ JSON isin_–§–∞–º–∏–ª–∏—è –ò.–û._start__end.json –≤ Data_work,
—á—Ç–µ–Ω–∏–µ –∏ –≤–∞–ª–∏–¥–∞—Ü–∏—è, –ø–µ—á–∞—Ç—å —Å—Ç–∞—Ç—É—Å–∞. –ù–∏–∫–∞–∫–æ–π –ª–æ–≥–∏–∫–∏ —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫–æ–≤/–∑–∞–ø–∏—Å–∏ –Ω–∞ –¥–∏—Å–∫.
"""

import os
import sys
import json
import re
import shutil
from datetime import datetime
from glob import glob
from pathlib import Path
from typing import Tuple, List, Dict, Any, Optional

# === –ê–≤—Ç–æ—É—Å—Ç–∞–Ω–æ–≤–∫–∞ rich –¥–ª—è —Ü–≤–µ—Ç–Ω–æ–≥–æ –≤—ã–≤–æ–¥–∞ ===
try:
    from rich.console import Console
    from rich import print
    from rich.table import Table
except ImportError:
    os.system(f'"{sys.executable}" -m pip install rich')
    from rich.console import Console
    from rich import print
    from rich.table import Table

console = Console()

# –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã –ø—É—Ç–µ–π (—Å–ª–µ–¥—É–µ–º –ø—Ä–∏–Ω—è—Ç–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–µ –ø—Ä–æ–µ–∫—Ç–∞)
BASE_DIR = r"F:\Python Projets\Report"
DATA_WORK = BASE_DIR + r"\Data_work"
DATA_BACKUP = BASE_DIR + r"\Data_Backup"
NAME_JSON = DATA_WORK + r"\name_clients.json"

# –ü—É—Ç–∏ –∫ —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫–∞–º
REF_STOCKS_XLSX = r"F:\Python Projets\Report\dictionaries\reference_stocks\reference_stocks_etf.xlsx"
REF_BONDS_XLSX  = r"F:\Python Projets\Report\dictionaries\reference_bonds\reference_bonds.xlsx"
REF_SP_XLSX     = r"F:\Python Projets\Report\dictionaries\reference_structured\TS\TS.xlsx"
REF_SP_PDF_DIR  = r"F:\Python Projets\Report\dictionaries\reference_structured\TS"

# ---------- –£—Ç–∏–ª–∏—Ç—ã ----------

def parse_payload_name_from_filename(path: Path) -> Tuple[str, str, str]:
    """
    –ò–∑ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞ –≤–∏–¥–∞:
      isin_–§–∞–º–∏–ª–∏—è –ò.–û._DD.MM.YYYY__DD.MM.YYYY.json
    –∏–∑–≤–ª–µ–∫–∞–µ—Ç (client_str, start_date, end_date).
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç—Ä–æ–∫–∏ –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π.
    """
    name = path.name
    # –ñ—ë—Å—Ç–∫–æ–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —à–∞–±–ª–æ–Ω—É
    m = re.fullmatch(r"isin_(.+)_(\d{2}\.\d{2}\.\d{4})__(\d{2}\.\d{2}\.\d{4})\.json", name)
    if not m:
        raise ValueError(f"–ò–º—è —Ñ–∞–π–ª–∞ –Ω–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç —à–∞–±–ª–æ–Ω—É: {name}")
    client_str, start_date, end_date = m.group(1), m.group(2), m.group(3)
    return client_str, start_date, end_date


def load_client_isins(path: Path) -> Tuple[str, Dict[str, str], List[str]]:
    """
    –ß–∏—Ç–∞–µ—Ç –≤—Ö–æ–¥–Ω–æ–π JSON –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
      client: —Å—Ç—Ä–æ–∫–∞ –∏–∑ JSON (–∫–∞–∫ –µ—Å—Ç—å)
      period: —Å–ª–æ–≤–∞—Ä—å {"start_date": "...", "end_date": "..."}
      isin_list: —Å–ø–∏—Å–æ–∫ ISIN
    –ë—Ä–æ—Å–∞–µ—Ç –æ—Å–º—ã—Å–ª–µ–Ω–Ω—ã–µ –æ—à–∏–±–∫–∏ –ø—Ä–∏ –ø—Ä–æ–±–ª–µ–º–∞—Ö —Å —á—Ç–µ–Ω–∏–µ–º/—Å—Ç—Ä—É–∫—Ç—É—Ä–æ–π.
    """
    try:
        with path.open("r", encoding="utf-8") as f:
            data = json.load(f)
    except FileNotFoundError:
        raise FileNotFoundError(f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {path}")
    except json.JSONDecodeError as e:
        raise ValueError(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON –≤ {path}: {e}")

    if not isinstance(data, dict):
        raise ValueError("–û–∂–∏–¥–∞–ª—Å—è –æ–±—ä–µ–∫—Ç JSON –≤–µ—Ä—Ö–Ω–µ–≥–æ —É—Ä–æ–≤–Ω—è")

    client = data.get("client")
    period = data.get("period")
    isins = data.get("isin")

    if not isinstance(client, str) or not client.strip():
        raise ValueError("–ü–æ–ª–µ 'client' –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –∏–ª–∏ –ø—É—Å—Ç–æ–µ")

    if not isinstance(period, dict) or "start_date" not in period or "end_date" not in period:
        raise ValueError("–ü–æ–ª–µ 'period' –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –∏–ª–∏ –Ω–µ–ø–æ–ª–Ω–æ–µ")

    if not isinstance(isins, list) or not all(isinstance(x, str) for x in isins):
        raise ValueError("–ü–æ–ª–µ 'isin' –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å —Å–ø–∏—Å–∫–æ–º —Å—Ç—Ä–æ–∫")

    return client, {"start_date": period["start_date"], "end_date": period["end_date"]}, isins


def find_input_payload(data_work: str) -> Path:
    """
    –ò—â–µ—Ç –≤—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª –ø–æ –º–∞—Å–∫–µ isin_*.json –≤ DATA_WORK.
    –ï—Å–ª–∏ –≤ –ø–∞–ø–∫–µ –µ—Å—Ç—å —Ñ–∞–π–ª—ã –¥—Ä—É–≥–∏—Ö –∫–ª–∏–µ–Ω—Ç–æ–≤, –æ–Ω–∏ –ø–µ—Ä–µ–º–µ—â–∞—é—Ç—Å—è –≤ Data_Backup.
    –î–ª—è —Ç–µ–∫—É—â–µ–≥–æ –∫–ª–∏–µ–Ω—Ç–∞ –¥–æ–ø—É—Å–∫–∞–µ—Ç—Å—è —Ä–æ–≤–Ω–æ –æ–¥–∏–Ω —Ñ–∞–π–ª; –∏–Ω–∞—á–µ ‚Äî –æ—à–∏–±–∫–∞.
    –ü—Ä–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–∏ name_clients.json —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è –ø—Ä–µ–∂–Ω—è—è –ª–æ–≥–∏–∫–∞ –≤—ã–±–æ—Ä–∞.
    """
    pattern = os.path.join(data_work, "isin_*.json")
    files = [Path(p) for p in glob(pattern) if os.path.isfile(p)]

    if not files:
        console.print(f"[red]‚ùå –í–æ –≤—Ö–æ–¥–Ω–æ–π –ø–∞–ø–∫–µ [/red][bright_cyan]{data_work}[/bright_cyan][red] –Ω–µ—Ç —Ñ–∞–π–ª–æ–≤ –ø–æ –º–∞—Å–∫–µ isin_*.json[/red]")
        sys.exit(1)

    # –ü—ã—Ç–∞–µ–º—Å—è –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Ç–µ–∫—É—â–µ–≥–æ –∫–ª–∏–µ–Ω—Ç–∞
    client = _read_current_client_from_namejson()

    # –ï—Å–ª–∏ –∫–ª–∏–µ–Ω—Ç–∞ –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –Ω–µ —É–¥–∞–ª–æ—Å—å ‚Äî —Ä–∞–±–æ—Ç–∞–µ–º –ø–æ –ø—Ä–µ–∂–Ω–µ–π —Å—Ö–µ–º–µ (–≤—ã–±—Ä–∞—Ç—å –æ–¥–∏–Ω, –æ—Å—Ç–∞–ª—å–Ω—ã–µ –≤ —Ä–µ–∑–µ—Ä–≤)
    if not client:
        keep, to_archive = _pick_isin_to_keep(files)
        console.print(f"[yellow]‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –∫–ª–∏–µ–Ω—Ç–∞ –ø–æ name_clients.json. "
                      f"–û—Å—Ç–∞–≤–ª—è—é —Å–∞–º—ã–π –ø–æ–¥—Ö–æ–¥—è—â–∏–π:[/yellow] [bright_cyan]{keep.name}[/bright_cyan]")
        _ensure_dir(Path(DATA_BACKUP))
        for old in to_archive:
            moved = _archive_path_to_backup(old)
            console.print(f"[yellow]‚Ü≥ –ü–µ—Ä–µ–º–µ—â—ë–Ω –≤ —Ä–µ–∑–µ—Ä–≤:[/yellow] [bright_cyan]{moved}[/bright_cyan]")
        return keep

    # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ —Ç–µ–∫—É—â–µ–º—É –∫–ª–∏–µ–Ω—Ç—É
    matching = [p for p in files if f"isin_{client}_" in p.name]
    foreign  = [p for p in files if p not in matching]

    # –í—Å–µ "—á—É–∂–∏–µ" –≤—Ö–æ–¥–Ω—ã–µ JSON ‚Äî –≤ —Ä–µ–∑–µ—Ä–≤
    if foreign:
        _ensure_dir(Path(DATA_BACKUP))
        for old in foreign:
            moved = _archive_path_to_backup(old)
            console.print(f"[yellow]‚ö†Ô∏è –ù–∞–π–¥–µ–Ω –≤—Ö–æ–¥–Ω–æ–π JSON –¥—Ä—É–≥–æ–≥–æ –∫–ª–∏–µ–Ω—Ç–∞, –ø–µ—Ä–µ–º–µ—â—ë–Ω –≤ —Ä–µ–∑–µ—Ä–≤:[/yellow] [bright_cyan]{moved}[/bright_cyan]")

    # –ü—Ä–æ–≤–µ—Ä–∫–∏ –ø–æ —Ç–µ–∫—É—â–µ–º—É –∫–ª–∏–µ–Ω—Ç—É
    if not matching:
        console.print(f"[red]‚ùå –î–ª—è –∫–ª–∏–µ–Ω—Ç–∞ [/red][bright_cyan]{client}[/bright_cyan][red] –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –Ω–∏ –æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ "
                      f"isin_{client}_*.json –≤ [/red][bright_cyan]{data_work}[/bright_cyan][red].[/red]")
        sys.exit(1)

    if len(matching) > 1:
        console.print(f"[red]‚ùå –ù–∞–π–¥–µ–Ω–æ –Ω–µ—Å–∫–æ–ª—å–∫–æ –≤—Ö–æ–¥–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ –¥–ª—è –∫–ª–∏–µ–Ω—Ç–∞ [/red][bright_cyan]{client}[/bright_cyan][red]:[/red]")
        for p in matching:
            console.print(f"[bright_cyan]  - {p.name}[/bright_cyan]")
        console.print("[yellow]–£–¥–∞–ª–∏ –ª–∏—à–Ω–∏–µ –∏–ª–∏ –ø–µ—Ä–µ–º–µ—Å—Ç–∏ –∏—Ö –≤ Data_Backup –∏ –ø–æ–≤—Ç–æ—Ä–∏ –∑–∞–ø—É—Å–∫.[/yellow]")
        sys.exit(1)

    # –†–æ–≤–Ω–æ –æ–¥–∏–Ω –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π —Ñ–∞–π–ª
    return matching[0]

# === –ê–≤—Ç–æ—É—Å—Ç–∞–Ω–æ–≤–∫–∞ openpyxl ===
try:
    from openpyxl import load_workbook
except ImportError:
    os.system(f'"{sys.executable}" -m pip install openpyxl')
    from openpyxl import load_workbook


def _norm_isin(s: str) -> str:
    return (s or "").strip().upper()


def load_reference_stocks(xlsx_path: str) -> dict:
    """
    –õ–∏—Å—Ç: '–∞–∫—Ü–∏–∏_etf'
    –ö–æ–ª–æ–Ω–∫–∏: A=ISIN, B=–¢–∏–∫–µ—Ä, C=–ù–∞–∑–≤–∞–Ω–∏–µ, D=–¢–∏–ø
    –í–æ–∑–≤—Ä–∞—Ç: { ISIN: {"ticker": str, "type": str, "name": str} }
    """
    wb = load_workbook(xlsx_path, read_only=True, data_only=True)
    if "–∞–∫—Ü–∏–∏_et—Ñ" in wb.sheetnames:
        ws = wb["–∞–∫—Ü–∏–∏_et—Ñ"]
    else:
        ws = wb["–∞–∫—Ü–∏–∏_etf"]  # –Ω–∞ —Å–ª—É—á–∞–π –æ–ø–µ—á–∞—Ç–æ–∫ —Ä–µ–≥–∏—Å—Ç—Ä–∞/—Ä–∞—Å–∫–ª–∞–¥–∫–∏
    ref = {}
    # –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ (–ø–µ—Ä–≤–∞—è —Å—Ç—Ä–æ–∫–∞)
    for row in ws.iter_rows(min_row=2, values_only=True):
        isin, ticker, name, typ = row[:4]
        isin = _norm_isin(isin)
        if not isin:
            continue
        ref[isin] = {
            "ticker": (ticker or "").strip(),
            "type": (typ or "").strip(),
            "name": (name or "").strip(),
        }
    return ref


def load_reference_bonds(xlsx_path: str) -> dict:
    """
    –õ–∏—Å—Ç: 'bonds'
    –ö–æ–ª–æ–Ω–∫–∏: A=ISIN, B=–ù–∞–∑–≤–∞–Ω–∏–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞
    –í–æ–∑–≤—Ä–∞—Ç: { ISIN: {"name": str} }
    """
    wb = load_workbook(xlsx_path, read_only=True, data_only=True)
    ws = wb["bonds"]
    ref = {}
    for row in ws.iter_rows(min_row=2, values_only=True):
        isin, name = row[:2]
        isin = _norm_isin(isin)
        if not isin:
            continue
        ref[isin] = {"name": (name or "").strip()}
    return ref


def load_reference_structured(xlsx_path: str, pdf_dir: str) -> dict:
    """
    –õ–∏—Å—Ç: 'TS'
    –ö–æ–ª–æ–Ω–∫–∏: B=ISIN, C=—Å—Å—ã–ª–∫–∞ (–Ω–µ–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–∞ –¥–ª—è –Ω–∞—Å)
    –í–æ–∑–≤—Ä–∞—Ç: { ISIN: {"pdf_path": <str|None>} }
    PDF —Ä–∞—Å–ø–æ–ª–∞–≥–∞—é—Ç—Å—è –≤ pdf_dir –∏ –∏–º–µ–Ω—É—é—Ç—Å—è '<ISIN>.pdf'
    """
    wb = load_workbook(xlsx_path, read_only=True, data_only=True)
    ws = wb["TS"]
    ref = {}
    for row in ws.iter_rows(min_row=2, values_only=True):
        # row: (N, ISIN, LINK, ...)
        _, isin, _ = (row + (None,))[:3]
        isin = _norm_isin(isin)
        if not isin:
            continue
        pdf_path = os.path.join(pdf_dir, f"{isin}.pdf")
        ref[isin] = {"pdf_path": pdf_path if os.path.isfile(pdf_path) else None}
    return ref


def match_isins(
    isins: List[str],
    ref_stocks: dict,
    ref_bonds: dict,
    ref_struct: dict,
) -> Tuple[List[dict], List[dict], List[dict], List[str]]:
    """
    –°–æ–ø–æ—Å—Ç–∞–≤–ª—è–µ—Ç ISIN –∏–∑ –≤—Ö–æ–¥–Ω–æ–≥–æ JSON —Å–æ —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫–∞–º–∏.
    –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç —Å—Ç—Ä–æ–≥–æ —Ç–∞–∫–æ–π (–æ–¥–∏–Ω ISIN ‚Üí –º–∞–∫—Å–∏–º—É–º –≤ –æ–¥–Ω—É –≥—Ä—É–ø–ø—É):
      1) –ê–∫—Ü–∏–∏/ETF
      2) –û–±–ª–∏–≥–∞—Ü–∏–∏
      3) –°—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã–µ –ø—Ä–æ–¥—É–∫—Ç—ã
      4) –ò–Ω–∞—á–µ ‚Äî –≤ 'misses'
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–æ—Ä—Ç–µ–∂ —Å–ø–∏—Å–∫–æ–≤:
      hits_stocks: list[{"isin","ticker","type"}]
      hits_bonds:  list[{"isin","name"}]
      hits_sp:     list[{"isin","type","pdf_path"}]  # type –≤—Å–µ–≥–¥–∞ "–°–¢–†–£–ö–¢–£–†–ù–´–ô –ü–†–û–î–£–ö–¢"
      misses:      list[isin]
    """
    seen = set()
    hits_stocks: List[dict] = []
    hits_bonds: List[dict] = []
    hits_sp: List[dict] = []
    misses: List[str] = []

    for raw in isins:
        isin = (raw or "").strip().upper()
        if not isin or isin in seen:
            continue
        seen.add(isin)

        # 1) Stocks/ETF
        s = ref_stocks.get(isin)
        if s:
            hits_stocks.append({
                "isin": isin,
                "ticker": s.get("ticker", ""),
                "name": s.get("name", ""),
                "type": s.get("type", ""),
            })
            continue

        # 2) Bonds
        b = ref_bonds.get(isin)
        if b:
            hits_bonds.append({
                "isin": isin,
                "name": b.get("name", ""),
            })
            continue

        # 3) Structured products
        sp = ref_struct.get(isin)
        if sp:
            hits_sp.append({
                "isin": isin,
                "type": "–°–¢–†–£–ö–¢–£–†–ù–´–ô –ü–†–û–î–£–ö–¢",
                "pdf_path": sp.get("pdf_path"),
            })
            continue

        # 4) –ù–µ –Ω–∞–π–¥–µ–Ω –Ω–∏ –≤ –æ–¥–Ω–æ–º —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫–µ
        misses.append(isin)

    return hits_stocks, hits_bonds, hits_sp, misses

# ---------- –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è –≠—Ç–∞–ø–∞ 4 ----------

def _ts_suffix() -> str:
    return datetime.now().strftime("%Y%m%d_%H%M%S")

def _ensure_dir(p: Path) -> None:
    p.mkdir(parents=True, exist_ok=True)

def build_output_paths(client: str, period: dict) -> dict:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª–æ–≤–∞—Ä—å —Å –∏–º–µ–Ω–∞–º–∏ –≤—ã—Ö–æ–¥–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ –∏ –∫–∞—Ç–∞–ª–æ–≥–æ–º –¥–ª—è SP.
    –í—Å–µ –∏–º–µ–Ω–∞ —Å—Ç—Ä–æ–≥–æ –ø–æ —à–∞–±–ª–æ–Ω–∞–º.
    """
    start = period["start_date"]
    end = period["end_date"]
    base = Path(DATA_WORK)
    return {
        "stocks_json": base / f"stock_etf_{client}_{start}__{end}.json",
        "bonds_json":  base / f"bonds_{client}_{start}__{end}.json",
        "sp_json":     base / f"sp_{client}_{start}__{end}.json",
        "noname_json": base / f"noname_isin_{client}_{start}__{end}.json",
        "sp_dir":      base / f"sp_{client}_{start}__{end}",
    }

def _archive_path_to_backup(path: Path) -> Path:
    """
    –ü–µ—Ä–µ–º–µ—â–∞–µ—Ç —Ñ–∞–π–ª/–ø–∞–ø–∫—É –≤ DATA_BACKUP —Å —Å—É—Ñ—Ñ–∏–∫—Å–æ–º '_—Ä–µ–∑–µ—Ä–≤_YYYYMMDD_HHMMSS'.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—É—Ç—å –≤ –±—ç–∫–∞–ø–µ.
    """
    _ensure_dir(Path(DATA_BACKUP))
    suffix = _ts_suffix()
    target_name = f"{path.stem}_—Ä–µ–∑–µ—Ä–≤_{suffix}{path.suffix}" if path.is_file() else f"{path.name}_—Ä–µ–∑–µ—Ä–≤_{suffix}"
    target = Path(DATA_BACKUP) / target_name
    shutil.move(str(path), str(target))
    return target

def archive_existing_outputs(paths: dict) -> None:
    """
    –ï—Å–ª–∏ –≤—ã—Ö–æ–¥–Ω—ã–µ JSON —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É—é—Ç ‚Äî –ø–µ—Ä–µ–º–µ—Å—Ç–∏—Ç—å –≤ Data_Backup.
    –ï—Å–ª–∏ –ø–∞–ø–∫–∞ SP —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç ‚Äî —Ç–∞–∫–∂–µ –ø–µ—Ä–µ–º–µ—Å—Ç–∏—Ç—å –≤ Data_Backup.
    """
    # JSON-—Ñ–∞–π–ª—ã
    for key in ("stocks_json", "bonds_json", "sp_json", "noname_json"):
        p = Path(paths[key])
        if p.exists():
            moved = _archive_path_to_backup(p)
            console.print(f"[yellow]‚ö†Ô∏è –ù–∞–π–¥–µ–Ω —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π —Ñ–∞–π–ª, –ø–µ—Ä–µ–º–µ—â–µ–Ω –≤ —Ä–µ–∑–µ—Ä–≤:[/yellow] [bright_cyan]{moved}[/bright_cyan]")

    # –ü–∞–ø–∫–∞ SP
    sp_dir = Path(paths["sp_dir"])
    if sp_dir.exists():
        moved = _archive_path_to_backup(sp_dir)
        console.print(f"[yellow]‚ö†Ô∏è –ù–∞–π–¥–µ–Ω–∞ —Å—É—â–µ—Å—Ç–≤—É—é—â–∞—è –ø–∞–ø–∫–∞ TermSheets, –ø–µ—Ä–µ–º–µ—â–µ–Ω–∞ –≤ —Ä–µ–∑–µ—Ä–≤:[/yellow] [bright_cyan]{moved}[/bright_cyan]")

def find_previous_sp_dirs(client: str, keep_dir: Path) -> list[Path]:
    """
    –ò—â–µ—Ç –≤ Data_work –≤—Å–µ –∫–∞—Ç–∞–ª–æ–≥–∏ –≤–∏–¥–∞ 'sp_{client}_*',
    –ö–†–û–ú–ï –∫–∞—Ç–∞–ª–æ–≥–∞ —Å –∏–º–µ–Ω–µ–º keep_dir.name (—Ü–µ–ª–µ–≤–æ–π –Ω–∞ —Ç–µ–∫—É—â–∏–π –∑–∞–ø—É—Å–∫).
    """
    pattern = Path(DATA_WORK) / f"sp_{client}_*"
    candidates = [Path(p) for p in glob(str(pattern))]
    return [p for p in candidates if p.is_dir() and p.name != keep_dir.name]

def find_all_sp_dirs_except(keep_dir: Path) -> list[Path]:
    """
    –ù–∞—Ö–æ–¥–∏—Ç –≤ Data_work –≤—Å–µ –∫–∞—Ç–∞–ª–æ–≥–∏ –ø–æ –º–∞—Å–∫–µ 'sp_*',
    –ö–†–û–ú–ï –∫–∞—Ç–∞–ª–æ–≥–∞ —Å –∏–º–µ–Ω–µ–º keep_dir.name (—Ü–µ–ª–µ–≤–æ–π —Ç–µ–∫—É—â–µ–≥–æ –∑–∞–ø—É—Å–∫–∞).
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è –æ—á–∏—Å—Ç–∫–∏ Data_work –æ—Ç –ø–∞–ø–æ–∫ –¥—Ä—É–≥–∏—Ö –∫–ª–∏–µ–Ω—Ç–æ–≤/–ø–µ—Ä–∏–æ–¥–æ–≤.
    """
    pattern = Path(DATA_WORK) / "sp_*"
    candidates = [Path(p) for p in glob(str(pattern))]
    return [p for p in candidates if p.is_dir() and p.name != keep_dir.name]

def archive_dirs_to_backup(dirs: list[Path]) -> None:
    """
    –ü–µ—Ä–µ–º–µ—â–∞–µ—Ç –ø–µ—Ä–µ—á–∏—Å–ª–µ–Ω–Ω—ã–µ –∫–∞—Ç–∞–ª–æ–≥–∏ –≤ Data_Backup
    —Å —Å—É—Ñ—Ñ–∏–∫—Å–æ–º '_—Ä–µ–∑–µ—Ä–≤_{YYYYMMDD_%H%M%S}'.
    """
    if not dirs:
        return
    _ensure_dir(Path(DATA_BACKUP))
    for src in dirs:
        moved = _archive_path_to_backup(src)
        console.print(f"[yellow]‚ö†Ô∏è –ù–∞–π–¥–µ–Ω–∞ —Å—Ç–∞—Ä–∞—è –ø–∞–ø–∫–∞ TermSheets, –ø–µ—Ä–µ–º–µ—â–µ–Ω–∞ –≤ —Ä–µ–∑–µ—Ä–≤:[/yellow] [bright_cyan]{moved}[/bright_cyan]")

def find_previous_jsons_for_client(client: str, period: dict, keep_paths: dict) -> list[Path]:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –í–°–ï–• JSON –≤ Data_work –¥–ª—è –¥–∞–Ω–Ω–æ–≥–æ –∫–ª–∏–µ–Ω—Ç–∞ –ø–æ –º–∞—Å–∫–∞–º:
      stock_etf_{client}_*.json
      bonds_{client}_*.json
      sp_{client}_*.json
      noname_isin_{client}_*.json
    –ö–†–û–ú–ï —Ç–µ–∫—É—â–∏—Ö —Ü–µ–ª–µ–≤—ã—Ö —Ñ–∞–π–ª–æ–≤ –∏–∑ keep_paths (–∏—Ö –∏–º–µ–Ω–∞ –∏—Å–∫–ª—é—á–∞–µ–º).
    """
    base = Path(DATA_WORK)
    patterns = [
        base / f"stock_etf_{client}_*.json",
        base / f"bonds_{client}_*.json",
        base / f"sp_{client}_*.json",
        base / f"noname_isin_{client}_*.json",
    ]
    keep_names = {
        Path(keep_paths["stocks_json"]).name,
        Path(keep_paths["bonds_json"]).name,
        Path(keep_paths["sp_json"]).name,
        Path(keep_paths["noname_json"]).name,
    }
    results = []
    for pat in patterns:
        for p in glob(str(pat)):
            pth = Path(p)
            if pth.is_file() and pth.name not in keep_names:
                results.append(pth)
    return results

def archive_jsons_to_backup(files: list[Path]) -> None:
    """
    –ü–µ—Ä–µ–º–µ—â–∞–µ—Ç –ø–µ—Ä–µ—á–∏—Å–ª–µ–Ω–Ω—ã–µ JSON-—Ñ–∞–π–ª—ã –≤ Data_Backup —Å —Å—É—Ñ—Ñ–∏–∫—Å–æ–º '_—Ä–µ–∑–µ—Ä–≤_YYYYMMDD_HHMMSS'.
    """
    if not files:
        return
    _ensure_dir(Path(DATA_BACKUP))
    for src in files:
        moved = _archive_path_to_backup(src)
        console.print(f"[yellow]‚ö†Ô∏è –ù–∞–π–¥–µ–Ω —Å—Ç–∞—Ä—ã–π JSON, –ø–µ—Ä–µ–º–µ—â–µ–Ω –≤ —Ä–µ–∑–µ—Ä–≤:[/yellow] [bright_cyan]{moved}[/bright_cyan]")

def find_foreign_jsons(client: str, keep_paths: dict) -> list[Path]:
    """
    –ù–∞—Ö–æ–¥–∏—Ç –í–°–ï JSON-—Ñ–∞–π–ª—ã –≤ Data_work (stock_etf_*, bonds_*, sp_*, noname_isin_*),
    –æ—Ç–Ω–æ—Å—è—â–∏–µ—Å—è –∫ –¥—Ä—É–≥–∏–º –∫–ª–∏–µ–Ω—Ç–∞–º (–∏–º—è —Ñ–∞–π–ª–∞ –ù–ï —Å–æ–¥–µ—Ä–∂–∏—Ç client),
    –∏ –Ω–µ —Å–æ–≤–ø–∞–¥–∞—é—â–∏–µ —Å —Ç–µ–∫—É—â–∏–º–∏ —Ü–µ–ª–µ–≤—ã–º–∏ –ø—É—Ç—è–º–∏ –∏–∑ keep_paths.
    """
    base = Path(DATA_WORK)
    patterns = [
        base / "stock_etf_*.json",
        base / "bonds_*.json",
        base / "sp_*.json",
        base / "noname_isin_*.json",
    ]
    keep_names = {
        Path(keep_paths["stocks_json"]).name,
        Path(keep_paths["bonds_json"]).name,
        Path(keep_paths["sp_json"]).name,
        Path(keep_paths["noname_json"]).name,
    }
    results = []
    for pat in patterns:
        for p in glob(str(pat)):
            pth = Path(p)
            # —á—É–∂–æ–π –∫–ª–∏–µ–Ω—Ç –∏ –Ω–µ —Ç–µ–∫—É—â–∏–µ —Ü–µ–ª–µ–≤—ã–µ –∏–º–µ–Ω–∞
            if pth.is_file() and (client not in pth.name) and (pth.name not in keep_names):
                results.append(pth)
    return results


def find_foreign_sp_dirs(client: str, keep_dir: Path) -> list[Path]:
    """
    –ù–∞—Ö–æ–¥–∏—Ç –≤—Å–µ –∫–∞—Ç–∞–ª–æ–≥–∏ sp_* –≤ Data_work, –∫–æ—Ç–æ—Ä—ã–µ –ù–ï –æ—Ç–Ω–æ—Å—è—Ç—Å—è –∫ client
    –∏ –Ω–µ —Å–æ–≤–ø–∞–¥–∞—é—Ç —Å keep_dir (—Ü–µ–ª–µ–≤–æ–π –∫–∞—Ç–∞–ª–æ–≥ —Ç–µ–∫—É—â–µ–≥–æ –∑–∞–ø—É—Å–∫–∞).
    """
    pattern = Path(DATA_WORK) / "sp_*"
    candidates = [Path(p) for p in glob(str(pattern))]
    return [p for p in candidates if p.is_dir() and (client not in p.name) and (p.name != keep_dir.name)]

def write_json_with_header(out_path: Path, client: str, period: dict, items: list) -> None:
    payload = {
        "client": client,
        "period": {"start_date": period["start_date"], "end_date": period["end_date"]},
        "items": items,
    }
    with out_path.open("w", encoding="utf-8") as f:
        json.dump(payload, f, ensure_ascii=False, indent=2)
    console.print(f"[green]üìù JSON –∑–∞–ø–∏—Å–∞–Ω:[/green] [bright_cyan]{out_path}[/bright_cyan]")

def copy_termsheets(hits_sp: list[dict], target_dir: Path) -> tuple[int, int]:
    """
    –ö–æ–ø–∏—Ä—É–µ—Ç —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ PDF –ø–æ –∏–º–µ–Ω–∞–º ISIN –≤ —Ü–µ–ª–µ–≤–æ–π –∫–∞—Ç–∞–ª–æ–≥.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (—Å–∫–æ–ø–∏—Ä–æ–≤–∞–Ω–æ, –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç).
    """
    _ensure_dir(target_dir)
    copied = 0
    missing = 0
    for rec in hits_sp:
        pdf = rec.get("pdf_path")
        isin = rec.get("isin", "")
        if pdf and os.path.isfile(pdf):
            dst = target_dir / f"{isin}.pdf"
            shutil.copy2(pdf, dst)
            copied += 1
        else:
            console.print(f"[yellow]‚ö†Ô∏è TermSheet –Ω–µ –Ω–∞–π–¥–µ–Ω –¥–ª—è ISIN:[/yellow] [bright_cyan]{isin}[/bright_cyan]")
            missing += 1
    return copied, missing

def _read_current_client_from_namejson() -> str | None:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç client_name –∏–∑ Data_work/name_clients.json, –ª–∏–±–æ None.
    """
    try:
        with open(NAME_JSON, "r", encoding="utf-8") as f:
            data = json.load(f)
        client = (data.get("client_name") or "").strip()
        return client or None
    except Exception:
        return None

def _pick_isin_to_keep(files: list[Path]) -> tuple[Path, list[Path]]:
    """
    –ò–∑ —Å–ø–∏—Å–∫–∞ isin_*.json –≤—ã–±–∏—Ä–∞–µ—Ç –æ–¥–∏–Ω, –∫–æ—Ç–æ—Ä—ã–π –æ—Å—Ç–∞–≤–ª—è–µ–º, –∏ —Å–ø–∏—Å–æ–∫ –æ—Å—Ç–∞–ª—å–Ω—ã—Ö –¥–ª—è –∞—Ä—Ö–∏–≤–∞—Ü–∏–∏.
    –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç:
      1) –µ—Å–ª–∏ –µ—Å—Ç—å name_clients.json ‚Äî –±–µ—Ä–µ–º —Å–∞–º—ã–π —Å–≤–µ–∂–∏–π —Ñ–∞–π–ª, –≥–¥–µ –∏–º—è —Å–æ–¥–µ—Ä–∂–∏—Ç 'isin_{client}_'
      2) –∏–Ω–∞—á–µ ‚Äî —Å–∞–º—ã–π —Å–≤–µ–∂–∏–π –ø–æ –≤—Ä–µ–º–µ–Ω–∏ –∏–∑–º–µ–Ω–µ–Ω–∏—è (mtime)
    """
    assert files, "files must be non-empty"
    client = _read_current_client_from_namejson()

    keep: Path | None = None
    if client:
        matching = [p for p in files if f"isin_{client}_" in p.name]
        if matching:
            keep = max(matching, key=lambda p: p.stat().st_mtime)

    if keep is None:
        keep = max(files, key=lambda p: p.stat().st_mtime)

    to_archive = [p for p in files if p != keep]
    return keep, to_archive

# ---------- –¢–æ—á–∫–∞ –≤—Ö–æ–¥–∞ ----------

def main(argv: Optional[List[str]] = None) -> int:
    try:
        console.print("[bold green]üß≠ map_instruments ‚Äî –≠—Ç–∞–ø 1 (–∫–∞—Ä–∫–∞—Å)[/bold green]")
        console.print(f"[bright_cyan]–ü–æ–∏—Å–∫ –≤—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ –≤: {DATA_WORK}[/bright_cyan]")

        input_path = find_input_payload(DATA_WORK)

        # –ò–º—è —Ñ–∞–π–ª–∞ ‚Üí –æ–∂–∏–¥–∞–µ–º—ã–µ client/start/end (–ø–æ –∏–º–µ–Ω–∏)
        client_from_name, start_from_name, end_from_name = parse_payload_name_from_filename(input_path)

        console.print(f"[green]‚úÖ –ù–∞–π–¥–µ–Ω –≤—Ö–æ–¥–Ω–æ–π JSON: [/green][bright_cyan]{input_path.name}[/bright_cyan]")
        console.print(f"[green]‚Ü≥ –û–∂–∏–¥–∞–µ—Ç—Å—è –∏–∑ –∏–º–µ–Ω–∏: client=[/green][bright_cyan]{client_from_name}[/bright_cyan][green], "
                      f"period=[/green][bright_cyan]{start_from_name}..{end_from_name}[/bright_cyan]")

        # –§–∞–∫—Ç–∏—á–µ—Å–∫–æ–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ JSON
        client, period, isins = load_client_isins(input_path)
        console.print(f"[green]‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω JSON. –ö–ª–∏–µ–Ω—Ç:[/green] [bright_cyan]{client}[/bright_cyan]")
        console.print(f"[green]‚Ü≥ –ü–µ—Ä–∏–æ–¥:[/green] [bright_cyan]{period['start_date']}..{period['end_date']}[/bright_cyan]")
        console.print(f"[green]‚Ü≥ –ö–æ–ª-–≤–æ ISIN:[/green] [bright_cyan]{len(isins)}[/bright_cyan]")

        # –ó–∞–≥—Ä—É–∑–∫–∞ —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫–æ–≤ (—Ç–æ–ª—å–∫–æ —á—Ç–µ–Ω–∏–µ, –±–µ–∑ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è)
        console.print(f"[green]üîÑ –ó–∞–≥—Ä—É–∑–∫–∞ —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫–æ–≤‚Ä¶[/green]")
        console.print(f"[green]‚Ü≥ Stocks/ETF:[/green] [bright_cyan]{REF_STOCKS_XLSX}[/bright_cyan]")
        stocks = load_reference_stocks(REF_STOCKS_XLSX)
        console.print(f"[green]   –ó–∞–≥—Ä—É–∂–µ–Ω–æ –∑–∞–ø–∏—Å–µ–π:[/green] [bright_cyan]{len(stocks)}[/bright_cyan]")

        console.print(f"[green]‚Ü≥ Bonds:[/green] [bright_cyan]{REF_BONDS_XLSX}[/bright_cyan]")
        bonds = load_reference_bonds(REF_BONDS_XLSX)
        console.print(f"[green]   –ó–∞–≥—Ä—É–∂–µ–Ω–æ –∑–∞–ø–∏—Å–µ–π:[/green] [bright_cyan]{len(bonds)}[/bright_cyan]")

        console.print(f"[green]‚Ü≥ Structured (TS):[/green] [bright_cyan]{REF_SP_XLSX}[/bright_cyan]")
        structured = load_reference_structured(REF_SP_XLSX, REF_SP_PDF_DIR)
        console.print(f"[green]   –ó–∞–≥—Ä—É–∂–µ–Ω–æ –∑–∞–ø–∏—Å–µ–π:[/green] [bright_cyan]{len(structured)}[/bright_cyan]")

        # –°–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ ISIN –ø–æ —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫–∞–º (–±–µ–∑ –∑–∞–ø–∏—Å–∏ –Ω–∞ –¥–∏—Å–∫)
        hits_stocks, hits_bonds, hits_sp, misses = match_isins(isins, stocks, bonds, structured)

        console.print("[green]üß© –†–µ–∑—É–ª—å—Ç–∞—Ç —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è:[/green]")
        console.print(f"  –ê–∫—Ü–∏–∏/ETF: [bright_cyan]{len(hits_stocks)}[/bright_cyan]")
        console.print(f"  –û–±–ª–∏–≥–∞—Ü–∏–∏: [bright_cyan]{len(hits_bonds)}[/bright_cyan]")
        console.print(f"  –°—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã–µ –ø—Ä–æ–¥—É–∫—Ç—ã: [bright_cyan]{len(hits_sp)}[/bright_cyan]")
        console.print(f"  –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–µ (noname): [bright_cyan]{len(misses)}[/bright_cyan]")

        # –ü–æ—Å—Ç–æ—è–Ω–Ω—ã–π –ø—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ (–ø–æ 3 –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º). –ó–∞–ø–∏—Å–∏ –Ω–µ –ø–∏—à—É—Ç—Å—è –Ω–∞ –¥–∏—Å–∫.
        preview_limit = 20

        def _render_table(title: str, columns: list[str], rows: list[list[str]]):
            if not rows:
                console.print(f"[yellow]{title}: –Ω–µ—Ç –∑–∞–ø–∏—Å–µ–π[/yellow]")
                return
            table = Table(title=title, show_lines=False)
            for col in columns:
                # –Ω–æ–º–µ—Ä –∫–æ–ª–æ–Ω–∫–∏ –∏ –∫–æ—Ä–æ—Ç–∫–∏–µ –ø–æ–ª—è –¥–µ–ª–∞–µ–º no_wrap –¥–ª—è –∞–∫–∫—É—Ä–∞—Ç–Ω–æ–≥–æ –≤–∏–¥–∞
                if col in ("‚Ññ", "ISIN", "Ticker", "Type"):
                    table.add_column(col, no_wrap=True)
                else:
                    table.add_column(col)
            for i, r in enumerate(rows[:preview_limit], 1):
                table.add_row(str(i), *r)
            console.print(table)

        # 1) –ü—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä: –ê–∫—Ü–∏–∏/ETF
        stock_rows = [
            [rec.get("isin", ""), rec.get("ticker", ""), rec.get("name", ""), rec.get("type", "")]
            for rec in hits_stocks
        ]
        _render_table("–ü—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä stock_etf (–±—É–¥—É—â–∏–π JSON)", ["‚Ññ", "ISIN", "Ticker", "Name", "Type"], stock_rows)

        # 2) –ü—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä: –û–±–ª–∏–≥–∞—Ü–∏–∏
        bond_rows = [
            [rec.get("isin", ""), rec.get("name", "")]
            for rec in hits_bonds
        ]
        _render_table("–ü—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä bonds (–±—É–¥—É—â–∏–π JSON)", ["‚Ññ", "ISIN", "Name"], bond_rows)

        # 3) –ü—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä: –°—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã–µ –ø—Ä–æ–¥—É–∫—Ç—ã
        sp_rows = [
            [rec.get("isin", ""), rec.get("type", "–°–¢–†–£–ö–¢–£–†–ù–´–ô –ü–†–û–î–£–ö–¢")]
            for rec in hits_sp
        ]
        _render_table("–ü—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä structured (–±—É–¥—É—â–∏–π JSON)", ["‚Ññ", "ISIN", "Type"], sp_rows)

        # === –≠—Ç–∞–ø 4: –∑–∞–ø–∏—Å—å –≤—ã—Ö–æ–¥–Ω—ã—Ö JSON –∏ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ TermSheets ===
        console.print("[green]üíæ –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –≤—ã—Ö–æ–¥–æ–≤ (JSON + TermSheets)‚Ä¶[/green]")

        # –ü–æ—Å—Ç—Ä–æ–∏—Ç—å –ø—É—Ç–∏ –∏ –∏–º–µ–Ω–∞
        paths = build_output_paths(client, period)

        # –ê—Ä—Ö–∏–≤–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–æ—à–ª—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã (–µ—Å–ª–∏ –µ—Å—Ç—å)
        archive_existing_outputs(paths)

        # –ê—Ä—Ö–∏–≤–∏—Ä–æ–≤–∞–Ω–∏–µ –≤—Å–µ—Ö –ø—Ä–æ—à–ª—ã—Ö JSON —ç—Ç–æ–≥–æ –∫–ª–∏–µ–Ω—Ç–∞ (—Å –¥—Ä—É–≥–∏–º–∏ –ø–µ—Ä–∏–æ–¥–∞–º–∏), –∫—Ä–æ–º–µ —Ç–µ–∫—É—â–∏—Ö
        old_jsons = find_previous_jsons_for_client(client, period, paths)
        archive_jsons_to_backup(old_jsons)

        # –ê—Ä—Ö–∏–≤–∏—Ä–æ–≤–∞—Ç—å –≤—Å–µ –ø—Ä–æ—à–ª—ã–µ –ø–∞–ø–∫–∏ TermSheets —ç—Ç–æ–≥–æ –∫–ª–∏–µ–Ω—Ç–∞ (—Å –¥—Ä—É–≥–∏–º–∏ –ø–µ—Ä–∏–æ–¥–∞–º–∏), –∫—Ä–æ–º–µ —Ç–µ–∫—É—â–µ–π
        old_sp_dirs = find_previous_sp_dirs(client, paths["sp_dir"])
        archive_dirs_to_backup(old_sp_dirs)

        # –ê—Ä—Ö–∏–≤–∏—Ä–æ–≤–∞—Ç—å JSON –∏ –ø–∞–ø–∫–∏ –¥—Ä—É–≥–∏—Ö –∫–ª–∏–µ–Ω—Ç–æ–≤ (–ø–æ–ª–Ω–∞—è —É–±–æ—Ä–∫–∞ —á—É–∂–∏—Ö –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤)
        foreign_jsons = find_foreign_jsons(client, paths)
        archive_jsons_to_backup(foreign_jsons)

        foreign_sp_dirs = find_foreign_sp_dirs(client, paths["sp_dir"])
        archive_dirs_to_backup(foreign_sp_dirs)

        # –ó–∞–ø–∏—Å—å —Ç—Ä–µ—Ö –æ—Å–Ω–æ–≤–Ω—ã—Ö JSON
        write_json_with_header(paths["stocks_json"], client, period, hits_stocks)
        write_json_with_header(paths["bonds_json"],  client, period, hits_bonds)
        write_json_with_header(paths["sp_json"],     client, period, hits_sp)

        # –ó–∞–ø–∏—Å—å noname JSON –ø—Ä–∏ –Ω–∞–ª–∏—á–∏–∏ –ø—Ä–æ–ø—É—Å–∫–æ–≤
        if misses:
            write_json_with_header(paths["noname_json"], client, period, [{"isin": m} for m in misses])
        else:
            console.print("[green]‚úÖ –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã—Ö ISIN –Ω–µ—Ç ‚Äî noname JSON –Ω–µ —Å–æ–∑–¥–∞–≤–∞–ª—Å—è[/green]")

        # –ö–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ TermSheets
        copied, missing = copy_termsheets(hits_sp, paths["sp_dir"])
        console.print(f"[green]üì¶ –ü–∞–ø–∫–∞ TermSheets:[/green] [bright_cyan]{paths['sp_dir']}[/bright_cyan]")
        console.print(f"[green]‚Ü≥ –°–∫–æ–ø–∏—Ä–æ–≤–∞–Ω–æ PDF:[/green] [bright_cyan]{copied}[/bright_cyan]; [yellow]–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç:[/yellow] [bright_cyan]{missing}[/bright_cyan]")

        console.print("[yellow]–≠—Ç–∞–ø 4 –∑–∞–≤–µ—Ä—à—ë–Ω: –≤—ã—Ö–æ–¥–Ω—ã–µ JSON —Å–æ–∑–¥–∞–Ω—ã, TermSheets —Å–∫–æ–ø–∏—Ä–æ–≤–∞–Ω—ã (—Å—Ç–∞—Ä—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω—ã –≤ Data_Backup).[/yellow]")
        return 0

    except KeyboardInterrupt:
        console.print("\n[red]–û–ø–µ—Ä–∞—Ü–∏—è –ø—Ä–µ—Ä–≤–∞–Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º[/red]")
        return 1
    except Exception as e:
        console.print(f"[red]‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}[/red]")
        return 1


if __name__ == "__main__":
    sys.exit(main())
